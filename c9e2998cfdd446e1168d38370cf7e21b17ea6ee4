{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "b5b41a47_2dc9c7fd",
        "filename": "src/serialization.c",
        "patchSetId": 7
      },
      "lineNbr": 2317,
      "author": {
        "id": 1017196
      },
      "writtenOn": "2021-07-02T07:41:01Z",
      "side": 1,
      "message": "question: why do you use a temporary variable here?",
      "range": {
        "startLine": 2317,
        "startChar": 40,
        "endLine": 2317,
        "endChar": 46
      },
      "revId": "c9e2998cfdd446e1168d38370cf7e21b17ea6ee4",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "8e794b66_92e2236a",
        "filename": "src/serialization.c",
        "patchSetId": 7
      },
      "lineNbr": 2317,
      "author": {
        "id": 1003556
      },
      "writtenOn": "2021-07-02T08:02:31Z",
      "side": 1,
      "message": "Good catch.\n\nHe actually needs another level of allocation here, which he why he uses parent as a static variable which will stay accessible after parse_link has finished; but that makes the function also invalidate any next parsed event which is kind of a non-starter when events will start being batched (e.g. it works now, but will likely silently corrupt data later)\n\nmemory allocations go:\n- fsevent (here, link) has been allocated by parse_fsevent called (e.g. src/sources/file.c)\n- parent, static here, which serve as intermediate container for...\n- parent.data, in the yaml event that is kept in rbh sstack for freeing when the next event is parsed --- this actually has the same problem for batching events and I conveniently didn\u0027t think about that :/\n\nreminder on type:\n\n struct rbh_fsevent {\n    ...\n    union {\n        ...\n    \n        struct {\n            /** The fsentry\u0027s parent ID */\n            const struct rbh_id *parent_id;\n            /** The fsentry\u0027s name */\n            const char *name;\n        } link, ns;\n    };\n };\n\n struct rbh_id {\n    const char *data;\n    size_t size;\n };\n\n\nfor the intermediate level, I actually don\u0027t see a good argument why the rbh_id isn\u0027t embed in the struct -- I assume it\u0027s so we can use the id from another fsevent directly? but that leaves lifetime problems so it\u0027d probably just as simple to copy, even if it makes the struct one size_t bigger... Quentin what do you think?\n\nfor the data itself, I think we\u0027ll need to think about it when dedup is implemented -- so off to Quentin\u0027s todo it goes?",
      "parentUuid": "b5b41a47_2dc9c7fd",
      "range": {
        "startLine": 2317,
        "startChar": 40,
        "endLine": 2317,
        "endChar": 46
      },
      "revId": "c9e2998cfdd446e1168d38370cf7e21b17ea6ee4",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "efd21abb_4dd7ad1a",
        "filename": "src/serialization.c",
        "patchSetId": 7
      },
      "lineNbr": 2317,
      "author": {
        "id": 1017196
      },
      "writtenOn": "2021-07-02T14:39:22Z",
      "side": 1,
      "message": "Thanks for the explanation!\n\nI understood why this is allocated, but I did not see/understand why this is not processed like the other fields:\n\n success \u003d parse_id(parser, \u0026link-\u003elink.parent_id);\n\nI will think about it again on next week, maybe the week-end will help :)!",
      "parentUuid": "8e794b66_92e2236a",
      "range": {
        "startLine": 2317,
        "startChar": 40,
        "endLine": 2317,
        "endChar": 46
      },
      "revId": "c9e2998cfdd446e1168d38370cf7e21b17ea6ee4",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "cf2a1f59_08b87c2d",
        "filename": "src/serialization.c",
        "patchSetId": 7
      },
      "lineNbr": 2317,
      "author": {
        "id": 1018755
      },
      "writtenOn": "2021-07-02T17:54:24Z",
      "side": 1,
      "message": "It is all part of the plan! ðŸ˜Ž\n\nThe behavior is documented in include/serialization.h:\n\n\u003e /* On success \\p fsevent\u0027s fields may point at static memory.\n\u003e  *\n\u003e  * Therefore, successive calls to parse_fsevents() will invalidate previously\n\u003e  * parsed fsevents. If one needs to eliminate pointers to static memory they\n\u003e  * should clone the fsevent.\n\u003e  */\n\u003e bool\n\u003e parse_fsevent(yaml_parser_t *parser, struct rbh_fsevent *fsevent);\n\nIn the future, when we need to process more than one fsevent at a time, the deduplicator will take care of memory allocations.\n\nI pondered this decision for quite a while, and I believe this is the best way to go about it:\n- the deduplicator and the sources don\u0027t have to cooperate on memory management;\n- makes writing sources much easier;\n- it doesn\u0027t look harder to optimize the source or the deduplicator, and optimizations benefit every source at once.\n\n\u003e for the intermediate level, I actually don\u0027t see a good argument why the rbh_id isn\u0027t embed in the struct -- I assume it\u0027s so we can use the id from another fsevent directly?\n\nIIUC, you mean that the caller of parse_fsevent() could provide a struct rbh_id as an argument?\n\nYou could do that, but `xattrs` can are not bounded in size, so the only way to parse them reliably without a series of:\n- try\n- not enough memory\n- increase buffer sizes\n- retry\n\nis to let parse_fsevent() do memory allocations itself.\n\n\u003e for the data itself, I think we\u0027ll need to think about it when dedup is implemented -- so off to Quentin\u0027s todo it goes?\n\nAh-ah! But I already figured out this part ðŸ˜Š\n\nIt\u0027s actually the last thing that was holding me off after the big yaml serialization thing. You\u0027ll have to wait until I actually start implementing a decent deduplicator to see it though (spoiler: there\u0027s gonna be a few ring buffers, at least one hashmap, and lots and lots of neat little tricks... Alright, maybe not that many tricks).",
      "parentUuid": "efd21abb_4dd7ad1a",
      "range": {
        "startLine": 2317,
        "startChar": 40,
        "endLine": 2317,
        "endChar": 46
      },
      "revId": "c9e2998cfdd446e1168d38370cf7e21b17ea6ee4",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "9bd7c7f3_8bade70b",
        "filename": "src/serialization.c",
        "patchSetId": 7
      },
      "lineNbr": 2317,
      "author": {
        "id": 1003556
      },
      "writtenOn": "2021-07-02T22:50:46Z",
      "side": 1,
      "message": "@SÃ©bastien: he could have done that if the memory had been allocated in parse_id instead, but parse_id can be called twice per event (main fsevent id + parent id) so I guess it was simpler to split? I don\u0027t think it really matters :)\n\n\u003e In the future, when we need to process more than one fsevent at a time, the deduplicator will take care of memory allocations.\n\nThat\u0027s basically doing allocations twice, with \"deep copy\" at dedup level? I actually think the opposite that it\u0027s much easier to do \"proper\" allocations here and just say all fields must be freed when the fsevent is freed...\n\nThe problem is made worse by your sstack allocations magic, because much of the memory pointed by the fsevents will still stay valid (from a C point of view) after the next event is parsed so asan/msan/valgrind won\u0027t detect anything if we forget to copy something and we\u0027ll just get silent corruption. And I\u0027ll need tons of tests to convince me it works, reviews don\u0027t replace tests. (thanksfully just doing a simple yaml-\u003eyaml dedup, no enrich phase of test should be trivial to add)\n\nYou\u0027re the one doing the work so meh, sure, it will work with enough care, but I can\u0027t bring myself to agree this is simpler. If later code is going to be doing memcpys and strcpys then I\u0027d just do that here instead of keeping events a bit longer as that\u0027s a false optimisation.\n\nWell, performance problems won\u0027t show until we start profiling with some tangible workload and I feel that filesystem ops will be the major slowdown whatever the design is taken, so my main worry is really just correctness; this deep copy phase is just making mistakes a bit easier.\n\n\u003e IIUC, you mean that the caller of parse_fsevent() could provide a struct rbh_id as an argument?\n\nno, I meant in general why was this field made a pointer. If it\u0027s always going to be filled on the spot, it\u0027s simpler to have it embed and not linking (struct rbh_id instead of struct rbh_id*); but I don\u0027t remember how it\u0027s used in other parts of rbh tools so there might have been a reason somewhere.\n\nReasoning being in general it\u0027s more efficient to make all allocations slightly bigger (+8 bytes) even if it means copying a bit more (16 bytes instead of setting a 8 bytes pointer), rather than make another tiny (16 bytes) allocation half the time.\n\n\u003e there\u0027s gonna be a few ring buffers, at least one hashmap, and lots and lots of neat little tricks... Alright, maybe not that many tricks\n\n(likewise I\u0027d rather keep the tricks as a later optimization and keep things simple, but if you have fun with it, well, sure :P)",
      "parentUuid": "cf2a1f59_08b87c2d",
      "range": {
        "startLine": 2317,
        "startChar": 40,
        "endLine": 2317,
        "endChar": 46
      },
      "revId": "c9e2998cfdd446e1168d38370cf7e21b17ea6ee4",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    }
  ]
}